{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG Exercise\n",
    "\n",
    "This notebook is designed as an exercise to build a complete Retrieval-Augmented Generation (RAG) system. In this exercise, you will integrate three main components into a single pipeline:\n",
    "\n",
    "1. **Retrieval Module** – Retrieve relevant documents based on a query.\n",
    "2. **Transformation Module** – Transform the retrieved queries.\n",
    "3. **Generation Module and Evaluation** – Use the transformed data to generate responses and evaluate the overall system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # For generating embeddings for text chunks\n",
    "import faiss\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Building the RAG Pipeline\n",
    "\n",
    "Load the data and store it in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "### load the pdf from the path\n",
    "glob_path = \"data/*.pdf\"\n",
    "text = \"\"\n",
    "for pdf_path in tqdm.tqdm(glob.glob(glob_path)):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "         # Extract text from all pages in the PDF\n",
    "        text += \" \".join(page.extract_text() for page in reader.pages if page.extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a splitter: 2000 characters per chunk with an overlap of 200 characters\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "# Split the full text into chunks\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 130\n",
      "Preview of the first chunk: Hyper tension in adul ts: \n",
      "diagnosis and manag emen t \n",
      "NICE guideline \n",
      "Published: 28 August 2019 \n",
      "Last updat ed: 21 No vember 2023 \n",
      "www .nice.or g.uk/guidance/ng136 \n",
      "© NICE 202 4. All right s reserved\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(\"Preview of the first chunk:\", chunks[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an embedding model\n",
    "Use the SentenceTransfomer wrapper as we have done so far.\n",
    "Models are found here: https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "or on HuggingFace.\n",
    "\n",
    "Embed the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Embed the original chunks (130 chunks)\n",
    "chunk_embeddings = model.encode(chunks, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Index and save index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in FAISS index: 130\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Build the FAISS index\n",
    "d = chunk_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(chunk_embeddings)\n",
    "print(\"Number of embeddings in FAISS index:\", index.ntotal)  # Should print 130\n",
    "\n",
    "# Save the index and chunks\n",
    "os.makedirs(\"faiss\", exist_ok=True)\n",
    "faiss.write_index(index, \"faiss/faiss_index.index\")\n",
    "with open(\"faiss/chunks_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Key for language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the API key using the variable name defined in the .env file\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build a retriever function\n",
    "\n",
    "arguments: query, k, index, chunks, embedding model\n",
    "\n",
    "return: retrieved texts, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k, index, chunks, model):\n",
    "    \"\"\"\n",
    "    Retrieve the top k similar text chunks and their distances for a given query.\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    retrieved_texts = [chunks[i] for i in indices[0]]\n",
    "    return retrieved_texts, distances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build an answer function\n",
    "Build an answer function that takes a query, k, an index and the chunks.\n",
    "\n",
    "return: answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query, k, index, chunks):\n",
    "    \"\"\"\n",
    "    Answer a query using retrieved chunks and an LLM.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks\n",
    "    retrieved_texts, distances = retrieve(query, k, index, chunks, model)\n",
    "    \n",
    "    # Combine the retrieved texts into a single context\n",
    "    context = \"\\n\".join(retrieved_texts)\n",
    "    \n",
    "    # Build the prompt for the language model\n",
    "    prompt = (\n",
    "        f\"Answer the following question based on the provided context:\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "    \n",
    "    # Use OpenAI to generate the answer\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    \n",
    "    try:\n",
    "        llm_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages\n",
    "        )\n",
    "        answer = llm_response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        answer = \"Error: Unable to generate an answer.\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer: The most important factor in diagnosing asthma is the demonstration of variable airflow obstruction, which can be assessed through various diagnostic tests such as measuring blood eosinophil counts, fractional exhaled nitric oxide (FeNO) levels, bronchodilator reversibility, or peak expiratory flow (PEF) variability. If asthma symptoms are suggestive, a combination of these tests is utilized to confirm the diagnosis.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What is the most important factor in diagnosing asthma?\"\n",
    "answer = answer_query(query, 5, index, chunks)\n",
    "print(\"LLM Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create a Rewriter\n",
    "\n",
    "Take a query and an api key for the model and rewrite the query. \n",
    "\n",
    "Rewriting a query: A Language Model is prompted to rewrite a query to better suit a task.\n",
    "\n",
    "Other Transfomrations are implemented in a similar fashion, this is just an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def rewrite_query(query, groq_api_key):\n",
    "    \"\"\"\n",
    "    Rewrite a query using Grok to make it more suitable for retrieval.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The original query.\n",
    "    - groq_api_key (str): The Groq API key.\n",
    "    \n",
    "    Returns:\n",
    "    - rewritten_query (str): The rewritten query.\n",
    "    \"\"\"\n",
    "    client = Groq(api_key=groq_api_key)\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Rewrite the following query to be clearer, more precise, and better suited for retrieving relevant information from a medical guideline document:\\n\\n\"\n",
    "        f\"Original Query: {query}\\n\\n\"\n",
    "        f\"Rewritten Query:\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    try:\n",
    "        llm_response = client.chat.completions.create(\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "            messages=messages,\n",
    "            max_tokens=150,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        rewritten_query = llm_response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error rewriting query with Grok: {e}\")\n",
    "        rewritten_query = query  # Fallback to original query\n",
    "    \n",
    "    return rewritten_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Implement the rewriter into your answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_rewriting(query, k, index, chunks, groq_api_key):\n",
    "    \"\"\"\n",
    "    Answer a query using a rewritten query (via Grok), retrieved chunks, and an LLM (OpenAI).\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The original query.\n",
    "    - k (int): Number of chunks to retrieve.\n",
    "    - index: The FAISS index.\n",
    "    - chunks (list): The list of text chunks (130 chunks).\n",
    "    - groq_api_key (str): The Groq API key for query rewriting.\n",
    "    \n",
    "    Returns:\n",
    "    - answer (str): The generated answer.\n",
    "    \"\"\"\n",
    "    # Rewrite the query using Grok\n",
    "    rewritten_query = rewrite_query(query, groq_api_key)\n",
    "    print(f\"Original Query: {query}\")\n",
    "    print(f\"Rewritten Query: {rewritten_query}\")\n",
    "    \n",
    "    # Retrieve relevant chunks using the rewritten query\n",
    "    retrieved_texts, distances = retrieve(rewritten_query, k, index, chunks, model)\n",
    "    \n",
    "    # Combine the retrieved texts into a single context\n",
    "    context = \"\\n\".join(retrieved_texts)\n",
    "    \n",
    "    # Build the prompt for the language model\n",
    "    prompt = (\n",
    "        f\"Answer the following question based on the provided context:\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Answer:\"\n",
    "    )\n",
    "    \n",
    "    # Use OpenAI to generate the answer\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "    \n",
    "    try:\n",
    "        llm_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages\n",
    "        )\n",
    "        answer = llm_response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        answer = \"Error: Unable to generate an answer.\"\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rewriting query with Grok: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Original Query: What is the most important factor in diagnosing asthma?\n",
      "Rewritten Query: What is the most important factor in diagnosing asthma?\n",
      "LLM Answer: The most important factor in diagnosing asthma is the objective testing of lung function, which includes measuring blood eosinophil counts, fractional exhaled nitric oxide (FeNO) levels, bronchodilator reversibility (BDR) through spirometry, and peak expiratory flow (PEF) variability. If asthma is suspected but not confirmed through these tests, further evaluations such as bronchial challenge tests may be conducted. Accurate diagnosis is crucial to ensuring appropriate management and treatment of the condition.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the most important factor in diagnosing asthma?\"\n",
    "answer = answer_query_with_rewriting(query, 5, index, chunks, groq_api_key)\n",
    "print(\"LLM Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 .Evaluation\n",
    "\n",
    "Select random chunks from all your chunks, and generate a question to each of these chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import httpx  # Ensure you're catching the correct timeout exception\n",
    "from openai import OpenAI\n",
    "def generate_questions_for_random_chunks(chunks, num_chunks=20, max_retries=3):\n",
    "    \"\"\"\n",
    "    Randomly selects a specified number of text chunks from the provided list,\n",
    "    then generates a question for each selected chunk using the Groq LLM.\n",
    "\n",
    "    Parameters:\n",
    "    - chunks (list): List of text chunks.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    - num_chunks (int): Number of chunks to select randomly (default is 20).\n",
    "\n",
    "    Returns:\n",
    "    - questions (list of tuples): Each tuple contains (chunk, generated_question).\n",
    "    \"\"\"\n",
    "    # Randomly select the desired number of chunks.\n",
    "    selected_chunks = random.sample(chunks, num_chunks)\n",
    "    \n",
    "    # Initialize the Groq client once\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    questions = []\n",
    "    for chunk in tqdm.tqdm(selected_chunks):\n",
    "        # Build a prompt that asks the LLM to generate a question based on the chunk.\n",
    "        prompt = (\n",
    "            \"Based on the following text, generate an insightful question that covers its key content:\\n\\n\"\n",
    "            \"Text:\\n\" + chunk + \"\\n\\n\"\n",
    "            \"Question:\"\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        generated_question = None\n",
    "        attempt = 0\n",
    "        \n",
    "        # Try calling the API with simple retry logic.\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                llm_response = client.chat.completions.create(\n",
    "                     model=\"gpt-4o-mini\",\n",
    "                    messages=messages\n",
    "                )\n",
    "                generated_question = llm_response.choices[0].message.content.strip()\n",
    "                break  # Exit the loop if successful.\n",
    "            except httpx.ReadTimeout:\n",
    "                attempt += 1\n",
    "                print(f\"Timeout occurred for chunk. Retrying attempt {attempt}/{max_retries}...\")\n",
    "                time.sleep(2)  # Wait a bit before retrying.\n",
    "        \n",
    "        # If all attempts fail, use an error message as the generated question.\n",
    "        if generated_question is None:\n",
    "            generated_question = \"Error: Failed to generate question after several retries.\"\n",
    "        \n",
    "        questions.append((chunk, generated_question))\n",
    "    \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "regular ICS plus SABA as needed. The committ ee therefore concluded t hat combination \n",
      "inhalers used...\n",
      "Generated Question: What are the implications of the new recommendations for using combination inhalers as preferred treatment for newly diagnosed asthma in adults, especially in relation to costs and potential reduction in severe exacerbations compared to current treatment options?\n",
      "\n",
      "Chunk 2:\n",
      "(NG2 45)\n",
      "© NICE 202 4. All right s reserved. Subject t o Notice of right s (https://www .nice.or g.u...\n",
      "Generated Question: What evidence influenced the committee's recommendation regarding the management of asthma in children, particularly in relation to dose adjustment of inhaled corticosteroids and the importance of personalized action plans?\n",
      "\n",
      "Chunk 3:\n",
      "diagnosis of ast hma who ar e stable on t heir curr ent t herap y do not ha ve to swit ch \n",
      "treatment...\n",
      "Generated Question: What changes in asthma treatment pathways are being recommended for individuals aged 12 and over, and how do these changes aim to improve patient outcomes and reduce healthcare costs?\n",
      "\n",
      "Chunk 4:\n",
      "put NICE guidance int o practice . Asthma: diagnosis, monit oring and chr onic ast hma management (B...\n",
      "Generated Question: What are the key updates and recommendations from NICE regarding asthma management, diagnosis, and monitoring, as highlighted in the November 2024 guidance?\n",
      "\n",
      "Chunk 5:\n",
      "blood pr essur e to lower tar gets in people wit h hyper tension (including t hose wit h type  2 \n",
      "di...\n",
      "Generated Question: What are the key updates in the NICE guidelines for managing hypertension and its implications for the treatment of patients with resistant hypertension and those with type 2 diabetes?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questions = generate_questions_for_random_chunks(chunks, num_chunks=5, max_retries=2)\n",
    "for idx, (chunk, question) in enumerate(questions, start=1):\n",
    "    print(f\"Chunk {idx}:\\n{chunk[:100]}...\\nGenerated Question: {question}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Test the questions with your built retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_generated_questions(question_tuples, k, index, texts, groq_api_key):\n",
    "    \"\"\"\n",
    "    For each (chunk, generated_question) tuple in the provided list, use the prebuilt\n",
    "    retrieval function to generate an answer for the generated question. The function\n",
    "    returns a list of dictionaries containing the original chunk, the generated question,\n",
    "    and the answer.\n",
    "    \n",
    "    Parameters:\n",
    "    - question_tuples (list of tuples): Each tuple is (chunk, generated_question)\n",
    "    - k (int): Number of retrieved documents to use for answering.\n",
    "    - index: The FAISS index.\n",
    "    - texts (list): The tokenized text chunks mapping.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    \n",
    "    Returns:\n",
    "    - results (list of dict): Each dict contains 'chunk', 'question', and 'answer'.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for chunk, question in question_tuples:\n",
    "        # Use your retrieval-based answer function. Here we assume the function signature is:\n",
    "        # answer_query(query, k, index, texts, groq_api_key)\n",
    "        answer = answer_query(question, k, index, texts) #query, k, index,texts\n",
    "        results.append({\n",
    "            \"chunk\": chunk,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Preview: regular ICS plus SABA as needed. The committ ee therefore concluded t hat combination \n",
      "inhalers used\n",
      "Generated Question: What are the implications of the new recommendations for using combination inhalers as preferred treatment for newly diagnosed asthma in adults, especially in relation to costs and potential reduction in severe exacerbations compared to current treatment options?\n",
      "Answer: The new recommendations for using combination inhalers as the preferred treatment for newly diagnosed asthma in adults have several important implications:\n",
      "\n",
      "1. **Reduction in Severe Exacerbations**: The evidence indicates that using combination inhalers (which include an inhaled corticosteroid (ICS) and a long-acting beta 2 agonist (LABA)) as needed leads to a significant reduction in severe asthma exacerbations compared to other treatment options, such as the use of short-acting beta agonists (SABA) alone or regular low-dose ICS plus SABA. This improvement in clinical outcomes emphasizes the importance of early intervention with combination therapy to manage asthma more effectively.\n",
      "\n",
      "2. **Cost-Effectiveness**: Health economic data suggests that treatment using the combination inhalers as needed is not only effective but also more cost-efficient than traditional methods, such as regular use of low-dose ICS plus SABA. The cost savings associated with fewer severe exacerbations and hospital visits can result in a net economic benefit for healthcare systems, making the adoption of combination therapy a financially sound decision in the long term.\n",
      "\n",
      "3. **Shift in Treatment Paradigm**: These recommendations represent a shift away from previously common practices that relied on SABA alone or on ICS used regularly without a comprehensive strategy. The integration of combination inhalers as a first-line treatment for newly diagnosed asthma can lead to better asthma control and potentially lower overall healthcare costs due to decreased exacerbations.\n",
      "\n",
      "4. **Guiding Clinical Practice**: The recommendations will encourage healthcare providers to reassess their current treatment strategies and prioritize combination inhalers for patients with newly diagnosed asthma. This may involve training and support for healthcare professionals to ensure they are informed about the new guidelines and understand the importance of individualized asthma management.\n",
      "\n",
      "In summary, the implications of the new recommendations are significant regarding improved patient outcomes through reduced severe exacerbations and potential cost savings, guiding a shift in clinical practice towards the use of combination inhalers for better management of newly diagnosed asthma.\n",
      "-----------------------------\n",
      "Chunk Preview: (NG2 45)\n",
      "© NICE 202 4. All right s reserved. Subject t o Notice of right s (https://www .nice.or g.u\n",
      "Generated Question: What evidence influenced the committee's recommendation regarding the management of asthma in children, particularly in relation to dose adjustment of inhaled corticosteroids and the importance of personalized action plans?\n",
      "Answer: The committee's recommendation regarding the management of asthma in children, particularly concerning dose adjustment of inhaled corticosteroids, was influenced by evidence reviewed in February 2020. This evidence indicated the need for a new recommendation on self-management in children and young people with asthma, leading to the removal of a prior recommendation related to increasing the dose of inhaled corticosteroids within a self-management program. \n",
      "\n",
      "Additionally, the committee emphasized the importance of personalized action plans, specifically highlighting that approaches to minimizing indoor air pollution and reducing exposure to outdoor air pollution should be included in these plans, as such pollution can trigger and exacerbate asthma symptoms. This decision was informed by the understanding that environmental factors significantly impact asthma management. \n",
      "\n",
      "Overall, the committee's recommendations aimed to improve clinical outcomes by ensuring that asthma management is tailored to the individual needs of children, taking into account both medication dosing and environmental influences.\n",
      "-----------------------------\n",
      "Chunk Preview: diagnosis of ast hma who ar e stable on t heir curr ent t herap y do not ha ve to swit ch \n",
      "treatment\n",
      "Generated Question: What changes in asthma treatment pathways are being recommended for individuals aged 12 and over, and how do these changes aim to improve patient outcomes and reduce healthcare costs?\n",
      "Answer: The recommended changes in asthma treatment pathways for individuals aged 12 and over include the following:\n",
      "\n",
      "1. **Avoidance of SABA Monotherapy**: Short-acting beta-2 agonists (SABAs) should not be used alone for asthma management. This recommendation stems from evidence demonstrating poor clinical outcomes associated with SABA monotherapy. The guidelines stress the importance of combining SABAs with inhaled corticosteroids (ICS) to reduce the risk of exacerbations and improve overall asthma control.\n",
      "\n",
      "2. **Increased Monitoring through FeNO Testing**: Before increasing treatment dosages, a fractional exhaled nitric oxide (FeNO) check is recommended, provided the necessary equipment is available. This practice aims to personalize treatment plans and ensure that medications are optimized based on the patient's inflammatory status.\n",
      "\n",
      "3. **Introduction of Digital Inhalers**: The utilization of digital smart inhalers may be explored to improve adherence to preventer inhalers. These inhalers use technology to monitor usage and provide feedback, potentially enhancing the patient's engagement with their treatment plan.\n",
      "\n",
      "These changes aim to improve patient outcomes by ensuring more comprehensive and effective asthma management, minimizing the reliance on ineffective treatments, and tailoring interventions to individual patient needs. Furthermore, by reducing exacerbation rates and improving control of asthma symptoms, these recommendations are expected to lead to lower healthcare costs associated with emergency department visits and hospital admissions. Overall, the emphasis is on proactive management and personalized care to enhance the quality of life for asthma patients aged 12 and over.\n",
      "-----------------------------\n",
      "Chunk Preview: put NICE guidance int o practice . Asthma: diagnosis, monit oring and chr onic ast hma management (B\n",
      "Generated Question: What are the key updates and recommendations from NICE regarding asthma management, diagnosis, and monitoring, as highlighted in the November 2024 guidance?\n",
      "Answer: The key updates and recommendations from NICE regarding asthma management, diagnosis, and monitoring highlighted in the November 2024 guidance include:\n",
      "\n",
      "1. **New Recommendations**: NICE has made new recommendations on diagnosis, treatment, and monitoring for people with asthma, marked as [BTS/NICE/SIGN 2024].\n",
      "\n",
      "2. **Changes Without Evidence Review**: Some recommendations have been amended without a formal evidence review. These amendments are marked accordingly, denoting modifications to existing guidelines.\n",
      "\n",
      "3. **Personalized Action Plans**: Recommendations include the necessity of incorporating approaches to minimize indoor and outdoor air pollution in personalized action plans, as pollution can trigger and exacerbate asthma symptoms.\n",
      "\n",
      "4. **Self-Management for Children**: A new recommendation was introduced for self-management in children and young people with asthma, specifically addressing the removal of a prior recommendation related to increasing inhaled corticosteroid doses.\n",
      "\n",
      "5. **Objective Testing**: For individuals presenting with acute asthma symptoms, immediate treatment is emphasized along with the performance of objective tests (such as eosinophil count, FeNO, spirometry, and peak expiratory flow) when equipment is available.\n",
      "\n",
      "6. **Avoiding SABA Monotherapy**: SABA (short-acting beta-2 agonists) should not be used alone for asthma management, as evidence shows that this practice results in poorer outcomes and increased risks.\n",
      "\n",
      "7. **Increased ICS Dosing**: For adults using an inhaled corticosteroid (ICS) in a single inhaler, an increased ICS dose should be offered for 7 days when asthma control deteriorates, with guidance on how and when to implement this change within the asthma action plan.\n",
      "\n",
      "8. **Education and Reviews**: Recommendations include reviewing personalized action plans during hospital admissions, consultations, and annual reviews to ensure that patients and caregivers understand the management strategies.\n",
      "\n",
      "These updates reflect a commitment to aligning asthma management practices with current best evidence to improve patient outcomes.\n",
      "-----------------------------\n",
      "Chunk Preview: blood pr essur e to lower tar gets in people wit h hyper tension (including t hose wit h type  2 \n",
      "di\n",
      "Generated Question: What are the key updates in the NICE guidelines for managing hypertension and its implications for the treatment of patients with resistant hypertension and those with type 2 diabetes?\n",
      "Answer: The key updates in the NICE guidelines for managing hypertension include specific blood pressure targets for various patient populations and recommendations for monitoring and treatment approaches. Notably:\n",
      "\n",
      "1. **Blood Pressure Targets**: \n",
      "   - For adults with hypertension (with or without type 2 diabetes), the target blood pressure goals are set according to specific conditions:\n",
      "     - For type 1 diabetes, the target is below 150/90 mmHg.\n",
      "     - For chronic kidney disease with an albumin to creatinine ratio less than 70 mg/mmol, the target is below 140/90 mmHg.\n",
      "     - For chronic kidney disease with an albumin to creatinine ratio of 70 mg/mmol or more, the target is below 130/80 mmHg.\n",
      "\n",
      "2. **Postural Hypotension**: The guidelines emphasize checking for postural hypotension in patients with hypertension, particularly in those with type 2 diabetes or aged 80 and over. Treatment should be based on standing blood pressure for those with significant drops or symptoms.\n",
      "\n",
      "3. **Self-Monitoring**: Patients with hypertension are encouraged to self-monitor their blood pressure using Home Blood Pressure Monitoring (HBPM), supported through relevant initiatives.\n",
      "\n",
      "4. **Use of ABPM**: The use of Ambulatory Blood Pressure Monitoring (ABPM) or HBPM in conjunction with clinic measurements is recommended for patients suspected of having \"white-coat effect\" or masked hypertension.\n",
      "\n",
      "5. **Treatment for Resistant Hypertension**: The guidelines provide direction on offering antihypertensive treatment when blood pressure remains uncontrolled, emphasizing the use of ACE inhibitors or ARBs for patients, particularly those with type 2 diabetes and those under 55 without Black African or African-Caribbean family origin.\n",
      "\n",
      "6. **Medication Safety**: There is a clear warning regarding the use of ACE inhibitors and ARBs in pregnancy and breastfeeding, stipulating that their use should be avoided unless absolutely necessary.\n",
      "\n",
      "For patients with **resistant hypertension** and **type 2 diabetes**, these updates imply a more comprehensive approach to monitoring and managing their blood pressure, adjusting targets based on individual conditions, and emphasizing the importance of self-monitoring and clinic-recommended measurements. The guidelines advocate for the careful selection of antihypertensive medications, considering safety and efficacy based on each patient's comorbidities and specific health needs.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "results = answer_generated_questions(questions, 5, index, chunks, groq_api_key)\n",
    "\n",
    "for item in results:\n",
    "    print(\"Chunk Preview:\", item['chunk'][:100])\n",
    "    print(\"Generated Question:\", item['question'])\n",
    "    print(\"Answer:\", item['answer'])\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluate_answers_binary(results, groq_api_key, max_retries=3):\n",
    "    \"\"\"\n",
    "    Evaluates each answer in the results list using an LLM.\n",
    "    For each result (a dictionary containing 'chunk', 'question', and 'answer'),\n",
    "    it sends an evaluation prompt to the Groq LLM which outputs 1 if the answer is on point,\n",
    "    and 0 if it is missing the point.\n",
    "    \n",
    "    Parameters:\n",
    "    - results (list of dict): Each dict must contain keys 'chunk', 'question', and 'answer'.\n",
    "    - groq_api_key (str): Your Groq API key.\n",
    "    - max_retries (int): Maximum number of retries if the API call times out.\n",
    "    \n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): A dataframe containing the original chunk, question, answer, and evaluation score.\n",
    "    \"\"\"\n",
    "    evaluations = []\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    for item in tqdm.tqdm(results, desc=\"Evaluating Answers\"):\n",
    "        # Build the evaluation prompt.\n",
    "        prompt = (\n",
    "            \"Evaluate the following answer to the given question. \"\n",
    "            \"If the answer is accurate and complete, reply with 1. \"\n",
    "            \"If the answer is inaccurate, incomplete, or otherwise not acceptable, reply with 0. \"\n",
    "            \"Do not include any extra text.\\n\\n\"\n",
    "            \"Question: \" + item['question'] + \"\\n\\n\"\n",
    "            \"Answer: \" + item['answer'] + \"\\n\\n\"\n",
    "            \"Context (original chunk): \" + item['chunk'] + \"\\n\\n\"\n",
    "            \"Evaluation (1 for good, 0 for bad):\"\n",
    "        )\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        \n",
    "        generated_eval = None\n",
    "        attempt = 0\n",
    "        \n",
    "        # Retry logic in case of timeouts or errors.\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                llm_response = client.chat.completions.create(\n",
    "                    messages=messages,\n",
    "                    model=\"gpt-4o-mini\"\n",
    "                )\n",
    "                generated_eval = llm_response.choices[0].message.content.strip()\n",
    "                break  # Exit the retry loop if successful.\n",
    "            except httpx.ReadTimeout:\n",
    "                attempt += 1\n",
    "                print(f\"Timeout occurred during evaluation. Retrying attempt {attempt}/{max_retries}...\")\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"Error during evaluation: {e}. Retrying attempt {attempt}/{max_retries}...\")\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # If no valid evaluation was produced, default to 0.\n",
    "        if generated_eval is None:\n",
    "            generated_eval = \"0\"\n",
    "        \n",
    "        # Convert the response to an integer (1 or 0).\n",
    "        try:\n",
    "            score = int(generated_eval)\n",
    "            if score not in [0, 1]:\n",
    "                score = 0\n",
    "        except:\n",
    "            score = 0\n",
    "        \n",
    "        evaluations.append(score)\n",
    "    \n",
    "    # Add the evaluation score to each result.\n",
    "    for i, item in enumerate(results):\n",
    "        item['evaluation'] = evaluations[i]\n",
    "    \n",
    "    # Create a dataframe for manual review.\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Answers:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Answers: 100%|██████████| 5/5 [00:03<00:00,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regular ICS plus SABA as needed. The committ e...</td>\n",
       "      <td>What are the implications of the new recommend...</td>\n",
       "      <td>The new recommendations for using combination ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(NG2 45)\\n© NICE 202 4. All right s reserved. ...</td>\n",
       "      <td>What evidence influenced the committee's recom...</td>\n",
       "      <td>The committee's recommendation regarding the m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diagnosis of ast hma who ar e stable on t heir...</td>\n",
       "      <td>What changes in asthma treatment pathways are ...</td>\n",
       "      <td>The recommended changes in asthma treatment pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>put NICE guidance int o practice . Asthma: dia...</td>\n",
       "      <td>What are the key updates and recommendations f...</td>\n",
       "      <td>The key updates and recommendations from NICE ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blood pr essur e to lower tar gets in people w...</td>\n",
       "      <td>What are the key updates in the NICE guideline...</td>\n",
       "      <td>The key updates in the NICE guidelines for man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  regular ICS plus SABA as needed. The committ e...   \n",
       "1  (NG2 45)\\n© NICE 202 4. All right s reserved. ...   \n",
       "2  diagnosis of ast hma who ar e stable on t heir...   \n",
       "3  put NICE guidance int o practice . Asthma: dia...   \n",
       "4  blood pr essur e to lower tar gets in people w...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are the implications of the new recommend...   \n",
       "1  What evidence influenced the committee's recom...   \n",
       "2  What changes in asthma treatment pathways are ...   \n",
       "3  What are the key updates and recommendations f...   \n",
       "4  What are the key updates in the NICE guideline...   \n",
       "\n",
       "                                              answer  evaluation  \n",
       "0  The new recommendations for using combination ...           1  \n",
       "1  The committee's recommendation regarding the m...           1  \n",
       "2  The recommended changes in asthma treatment pa...           1  \n",
       "3  The key updates and recommendations from NICE ...           1  \n",
       "4  The key updates in the NICE guidelines for man...           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_evaluations = evaluate_answers_binary(results, openai_api_key)\n",
    "display(df_evaluations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
